{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Title: PixelCNN\n",
    "Author: [ADMoreau](https://github.com/ADMoreau)\n",
    "Date created: 2020/05/17\n",
    "Last modified: 2020/05/23\n",
    "Description: PixelCNN implemented in Keras.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Introduction\n",
    "PixelCNN is a generative model proposed in 2016 by van den Oord et al.\n",
    "(reference: [Conditional Image Generation with PixelCNN Decoders](https://arxiv.org/abs/1606.05328)).\n",
    "It is designed to generate images (or other data types) iteratively\n",
    "from an input vector where the probability distribution of prior elements dictates the\n",
    "probability distribution of later elements. In the following example, images are generated\n",
    "in this fashion, pixel-by-pixel, via a masked convolution kernel that only looks at data\n",
    "from previously generated pixels (origin at the top left) to generate later pixels.\n",
    "During inference, the output of the network is used as a probability ditribution\n",
    "from which new pixel values are sampled to generate a new image\n",
    "(here, with MNIST, the pixels values are either black or white).\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0-dev20211207'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "## Getting the Data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 1)\n",
    "n_residual_blocks = 5\n",
    "# The data, split between train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "(70000, 28, 28)\n",
      "(70000, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Round all pixel values less than 33% of the max 256 value to 0\n",
    "# anything above this value gets rounded up to 1 so that all values are either\n",
    "# 0 or 1\n",
    "#data = np.where(data < (0.33 * 256), 0, 1)\n",
    "(x, _), (y, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Concatenate all of the images together\n",
    "data = np.concatenate((x, y), axis=0)\n",
    "\n",
    "data = data.astype(np.float32)\n",
    "print(data.shape)\n",
    "data = data[:, 10, :].reshape(data.shape[0], 28,1)\n",
    "\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f27b359af50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Code for the TCN adapted from https://github.com/philipperemy/keras-tcn\n",
    "\n",
    "def residual_block(x, training, dilation_rate, nb_filters, kernel_size, padding,\n",
    "                   activation='relu', dropout_rate=0, use_batch_norm=False):\n",
    "    # type: (Layer, bool, int, int, int, str, str, float, str, bool) -> Tuple[Layer, Layer]\n",
    "    \"\"\"Defines the residual block for the WaveNet TCN\n",
    "    Args:\n",
    "        x: The previous layer in the model\n",
    "        training: boolean indicating whether the layer should behave in training mode or in inference mode\n",
    "        dilation_rate: The dilation power of 2 we are using for this residual block\n",
    "        nb_filters: The number of convolutional filters to use in this block\n",
    "        kernel_size: The size of the convolutional kernel\n",
    "        padding: The padding used in the convolutional layers, 'same' or 'causal'.\n",
    "        activation: The final activation used in o = Activation(x + F(x))\n",
    "        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "        kernel_initializer: Initializer for the kernel weights matrix (Conv1D).\n",
    "        use_batch_norm: Whether to use batch normalization in the residual layers or not.\n",
    "    Returns:\n",
    "        A tuple where the first element is the residual model layer, and the second\n",
    "        is the skip connection.\n",
    "    \"\"\"\n",
    "    prev_x = x\n",
    "    for k in range(2):\n",
    "        x = tf.keras.layers.Conv1D(filters=nb_filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   dilation_rate=dilation_rate,\n",
    "                   padding=padding,\n",
    "                   activation=activation)(x)\n",
    "        if use_batch_norm:\n",
    "            x = tf.layers.batch_normalization(x)  # TODO should be WeightNorm here, but using batchNorm instead\n",
    "        #x = tf.nn.relu(x)\n",
    "        x = tf.keras.layers.SpatialDropout1D(rate=dropout_rate)(inputs=x, training=training)\n",
    "\n",
    "    # 1x1 conv to match the shapes (channel dimension).\n",
    "    prev_x = tf.keras.layers.Conv1D(nb_filters, 1, padding='same')(prev_x)\n",
    "    res_x = prev_x + x\n",
    "    res_x = tf.keras.activations.relu(res_x)\n",
    "    return res_x, x\n",
    "\n",
    "def process_dilations(dilations):\n",
    "    def is_power_of_two(num):\n",
    "        return num != 0 and ((num & (num - 1)) == 0)\n",
    "\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        return new_dilations\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(nb_filters, 1, padding=padding)(x)\n",
    "    skip_connections = []\n",
    "    for s in range(nb_stacks):\n",
    "        for d in dilations:\n",
    "            x, skip_out = residual_block(training=training,\n",
    "                                          dilation_rate=d,\n",
    "                                          nb_filters=nb_filters,\n",
    "                                          kernel_size=kernel_size,\n",
    "                                          padding=padding,\n",
    "                                          activation=activation,\n",
    "                                          dropout_rate=dropout_rate,\n",
    "                                          use_batch_norm=use_batch_norm)(x)\n",
    "            skip_connections.append(skip_out)\n",
    "    if use_skip_connections:\n",
    "        x = tf.keras.layers.add(skip_connections)\n",
    "    if not return_sequences:\n",
    "        x = x[:, -1, :]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[batch_size, 100, 1])\n",
    "\n",
    "net = tcn(x, return_sequences=True)\n",
    "net = tf.layers.dense(net, 2)\n",
    "\n",
    "distribution = tfp.distributions.Normal(net[...,0], 1e-4 + tf.nn.softplus(net[..., 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 2\n",
    "# Shape of the distribution\n",
    "event_shape = [1]\n",
    "# Utility function to compute how many parameters this distribution requires\n",
    "params_size = tfp.layers.MixtureNormal.params_size(num_components, event_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(params_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Build the model based on the original paper\n",
    "\"\"\"\n",
    "\n",
    "inputs = keras.Input(shape=(28,1), dtype='float32')\n",
    "\n",
    "kernel_size=3\n",
    "\n",
    "x = tf.keras.layers.Conv1D(filters=16,\n",
    "           kernel_size=kernel_size,\n",
    "           dilation_rate=1,\n",
    "           padding='causal',\n",
    "           activation='relu')(inputs)\n",
    "\n",
    "for dilation_rate, nb_filters in zip([2, 4, 8, 16, 32], [16, 32, 64, 128, 256]):\n",
    "    x = tf.keras.layers.Conv1D(filters=nb_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               dilation_rate=dilation_rate,\n",
    "               padding='causal',\n",
    "               activation='relu')(x)\n",
    "\n",
    "\n",
    "\n",
    "x = keras.layers.Dense(params_size)(x)\n",
    "out = tfp.layers.MixtureNormal(num_components, event_shape)(x)\n",
    "\n",
    "pixel_cnn = keras.Model(inputs, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 28, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 28, 16)            64        \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 28, 16)            784       \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 28, 32)            1568      \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 28, 64)            6208      \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 28, 128)           24704     \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 28, 256)           98560     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 28, 6)             1542      \n",
      "                                                                 \n",
      " mixture_normal_2 (MixtureNo  ((None, 28, 1),          0         \n",
      " rmal)                        (None, 28, 1))                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,430\n",
      "Trainable params: 133,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pixel_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "negloglik = lambda y, q: -q.log_prob(y)\n",
    "\n",
    "pixel_cnn.compile(loss=negloglik, optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 [==============================] - 55s 25ms/step - loss: 7.4431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2718774ad0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_cnn.fit(data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAAD4CAYAAABFew5gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAICUlEQVR4nO2dbYwdVRnHf//d7vZl2Zpu165ESiy1yEuoVSs28mWNhlSiQZpo6AfTiBFjim/hg02JiokfSHwhmKDJog0YqRWR0kYqUNGEkIjYlha21mrdLLi0ti4NZdvd7uvjh5lr7i479+XM3LnHyfklN/fOnDPPOf89Z+acnWeeMzIz/t9paXYFsiCI8IUgwhcW5FrYog5r7+xKTB8bHho2s7fXbTdNpSRtBO4DWoGfmtk9lfK3d3Zx1aavJ6a/2HfnKy71cO5OklqB+4GPA9cAmyVd42ovDWnOieuBE2Y2YGYTwC7g5myqVR9pRLwT+FfZ9lC8bxaSbpd0QNKBqYsXUhSXTBoRmmffW+YwZtZnZuvNbP2CRR0piksmjYghYGXZ9mXAyXTVcSONiL8AayStktQO3ArszaZa9eF8iTWzKUl3AE8RXWJ3mNnR6ge6lphMqnHCzPYB+zKqizOFmHYEEb4QRPhCIUTk+v/EshUjbPrKHxLTX3zAzW4hWiKI8IUgwhcKISLXS+zbWkf5xNIjienfdLRbiJYIInwhiPCFIMIXch0nXuvv5BtX9VbI8Qsnu4VoiSDCF4IIXwgifCHXccIAm57J3G5aF/AgMAJMA1Nmtj6LStVLFi3xETMbzsCOM4U4J9KKMOBpSQcl3T5fhnIX8KRdTFnc/KTtTjeY2UlJK4D9kv5mZs+WZzCzPqAPYGnL8oY85paqJczsZPx9BthN9JRB7qR5tqNDUmfpN3Aj0J9VxeohTXfqAXZLKtnZaWZPVjpgumsJZz/5geQMD+50qkgaP/YA8F7X47MkXGJ9IYjwhUKIyHUq3np2lK5dhzK3W4iWCCJ8IYjwhSDCF3IdJ9TaSsvSpckZHP97LURLBBG+EET4QhDhC7mOE2Bg2d/aL0RLBBG+EET4QhDhC/m6gKenmXnjXOZ2q7aEpB2SzkjqL9vXJWm/pH/E38syr1kd1NKdHgQ2ztm3DXjGzNYAz8TbTaOqiNiReHbO7puBh+LfDwGfyrZa9eF6YveY2SmA+HtFUsbZLuBxx+Iq0/CrU3kUcJsWNqQMVxGnJV0KEH+fya5K9eMqYi+wJf69BdiTTXXcULW1bCT9EugFuoHTwLeBx4FHgMuBV4FPm9nck/8trF3bZnv3dSemr1r574MuT+pUHezMbHNC0kfrLaxRFGLaEUT4QhDhC7lOxQcHe7hty9YKObY72S1ESwQRvhBE+EIQ4Qv53to/P8aC57J/6rQQLRFE+EIQ4QtBhC/kO06YYZMTmZstREsEEb4QRPhCEOELuY4TM8s6OH/jhuQMv3rUya6rC/huSa9JOhx/bnIqPSNcXcAA95rZuvjT1JVKXV3AXpHmxL5D0ktxd0t8omCWC3jcr4WgfwKsBtYBp4AfJGWc5QJe6NFC0GZ22symzWwGeIAmRf+WcBJR8mHH3EKTon9LVB0nyl3AkoaIXMC9ktYRRcYPAl+spbCWN0bp3J19iJqrC/hnmdckBYWYdgQRvhBE+EKuU/Err7vAk0+9kJjeemliUkUK0RJBhC8EEb4QRPhCruPE31/uYOOqD1XIccLJbiFaIojwhSDCF4IIX8h1nJhavoThTe9PztD3sJPdQrREEOELQYQvBBG+kOs4Mb0Qzr07e7u1uIBXSvqjpGOSjkr6arzfm0jgWrrTFHCnmV0NbAC2xu/89SYSuBYX8CkzOxT/HgGOEb0u15tI4LpObEnvAt4H/JkaI4HLXcAzF5rsApZ0CfAb4Gtm9matx5W7gFs6mugCltRGJOBhM3ss3u1NJHAt3lMRORqPmdkPy5JKkcD3UGMkcNso9LyQvCDPQDUDCdQyTtwAfBZ4WdLheN92oso/IunzxJHAjnVITS0u4OeY/13Y4EkkcCGmHUGELwQRvlB1oYUsuW5tmz32RPJCC1de7rbQQiFaIojwhSDCF4IIX8j1ls0r/Z1sXd1bIccuJ7uFaIkgwheCCF8IInwh13Gi59oxvrwnOUph/2o3u4VoiSDCF4IIXwgifKEW/8RK4OfAO4AZoM/M7pN0N/AF4D9x1u3VYlBP9y/mR2uurpDDLdKtlsGu5D09FL9d86Ck/XHavWb2faeSM6QW/8QpotBMzGxEUsl76g1pvKdQQxDtrABamryG8jze05qCaGcF0NLENZTn8576FERby7Md83pPfQqiTeM93ewSRIuyH5rSeE+bui5BOYUYsYMIXwgifCGI8IUgwheCCF8IInyhECJyfVRI0ghwvGxXNzBctv0eM+us127OL6rkePnzTJIOzN12MVqI7hREONBX53ZN5HpiN4rQnXyhoSLi4KlDkiYkjUr6jqSNko5LOiFpmyLelDQuaUzSoKRzZetufqtqQWbWsA/wPeB14ArgLqJAkVfj7XbgCNFNt1GigW8D8Ffgt/WU0+ju9BngJTMbAHYAbcBFMxswswmip7RuAy7Ef9DngUugvjvPjRbRDfwT/ufnWAxMlqUPEQVUTQJPSzpIdFv0g5KOSPqdpGurFZJ62iHp90SusLncVasJ4EtmtkfSCiLR28zs/ngd2seBNZUMpBZhZh9LrJ00TOTDKN1FHyPqUiUuI3rR35LY1hlJ48Thbma2T9KPJXWb2TAJNLo7/RpYK2kVUd+fBBZLWiWpHbgV2Al8Lr5K9QKLgD8BSLo+ruPrFUtp8NVpOXAYmCC6An0XuInI4zpO1OWuAM7HAi8CzwJHia5czwMfrlZOmHb4QhDhC0GELwQRvvBfpxBMBRUW2PIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26601d0bd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = np.random.random((28,1))\n",
    "plt.imshow(pixel_cnn.predict(seq).reshape(28,1))\n",
    "plt.show()\n",
    "plt.imshow(seq)\n",
    "plt.show()\n",
    "plt.imshow(seq-pixel_cnn.predict(seq).reshape(28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f266020dc50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(seq, vmin=-5, vmax=5, cmap='jet', aspect='auto')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(pixel_cnn.predict(seq).reshape(28,1), vmin=-5, vmax=5, cmap='jet', aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(28, 1, 1), dtype=float32, numpy=\n",
       "array([[[ 2.0971757e-01]],\n",
       "\n",
       "       [[ 2.0853369e-01]],\n",
       "\n",
       "       [[ 5.7056743e-01]],\n",
       "\n",
       "       [[ 5.2681899e-01]],\n",
       "\n",
       "       [[ 1.1434085e-02]],\n",
       "\n",
       "       [[-1.4872286e-03]],\n",
       "\n",
       "       [[ 1.9894464e-01]],\n",
       "\n",
       "       [[ 6.9658109e-03]],\n",
       "\n",
       "       [[ 2.4975747e-02]],\n",
       "\n",
       "       [[ 3.4848716e-02]],\n",
       "\n",
       "       [[ 4.1500636e-05]],\n",
       "\n",
       "       [[ 6.5648180e-01]],\n",
       "\n",
       "       [[ 1.0504401e-01]],\n",
       "\n",
       "       [[ 2.4598925e-03]],\n",
       "\n",
       "       [[-3.7073959e-03]],\n",
       "\n",
       "       [[ 1.7077190e-01]],\n",
       "\n",
       "       [[ 3.3144313e-03]],\n",
       "\n",
       "       [[ 6.1454052e-01]],\n",
       "\n",
       "       [[ 1.5206153e-02]],\n",
       "\n",
       "       [[ 1.9228107e-01]],\n",
       "\n",
       "       [[ 2.7804214e-01]],\n",
       "\n",
       "       [[ 1.6186319e-01]],\n",
       "\n",
       "       [[ 6.1516356e-01]],\n",
       "\n",
       "       [[-1.7056708e-01]],\n",
       "\n",
       "       [[ 5.4616743e-01]],\n",
       "\n",
       "       [[ 2.5906002e-03]],\n",
       "\n",
       "       [[-2.8486946e-03]],\n",
       "\n",
       "       [[-3.9793984e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_cnn(seq).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MixtureNormal' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9a8e655d0baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpixel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MixtureNormal' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "pixel_cnn.layers[-1].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Build the model based on the original paper\n",
    "\"\"\"\n",
    "\n",
    "inputs = keras.Input(shape=(28,1))\n",
    "x = PixelConvLayer(\n",
    "    mask_type=\"A\", filters=128, kernel_size=7, activation=\"relu\", padding=\"same\"\n",
    ")(inputs)\n",
    "\n",
    "for _ in range(n_residual_blocks):\n",
    "    x = ResidualBlock(filters=128)(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    x = PixelConvLayer(\n",
    "        mask_type=\"B\",\n",
    "        filters=128,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        activation=\"relu\",\n",
    "        padding=\"valid\",\n",
    "    )(x)\n",
    "\n",
    "#out = keras.layers.Conv1D(\n",
    "#    filters=1, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"valid\"\n",
    "#)(x)\n",
    "\n",
    "out = tfp.layers.MixtureNormal(num_components, event_shape)(x)\n",
    "\n",
    "\n",
    "pixel_cnn = keras.Model(inputs, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negloglik = lambda y, q: -q.log_prob(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 1)]           0         \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer (PixelConvL (None, 28, 128)           1024      \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "residual_block_2 (ResidualBl (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "residual_block_3 (ResidualBl (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "residual_block_4 (ResidualBl (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_6 (PixelCon (None, 28, 128)           16512     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_7 (PixelCon (None, 28, 128)           16512     \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 28, 1)             129       \n",
      "=================================================================\n",
      "Total params: 281,537\n",
      "Trainable params: 281,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "pixel_cnn.compile(optimizer=adam, loss=negloglik)\n",
    "\n",
    "pixel_cnn.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(pixel_cnn, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn.fit(\n",
    "    x=data, y=data, batch_size=128, epochs=50, validation_split=0.1, verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Demonstration\n",
    "The PixelCNN cannot generate the full image at once. Instead, it must generate each pixel in\n",
    "order, append the last generated pixel to the current image, and feed the image back into the\n",
    "model to repeat the process.\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Create an empty array of pixels.\n",
    "batch = 4\n",
    "pixels = np.zeros(shape=(batch,) + (pixel_cnn.input_shape)[1:])\n",
    "batch, rows, cols, channels = pixels.shape\n",
    "\n",
    "# Iterate over the pixels because generation has to be done sequentially pixel by pixel.\n",
    "for row in tqdm(range(rows)):\n",
    "    for col in range(cols):\n",
    "        for channel in range(channels):\n",
    "            # Feed the whole array and retrieving the pixel value probabilities for the next\n",
    "            # pixel.\n",
    "            probs = pixel_cnn.predict(pixels)[:, row, col, channel]\n",
    "            # Use the probabilities to pick pixel values and append the values to the image\n",
    "            # frame.\n",
    "            pixels[:, row, col, channel] = tf.math.ceil(\n",
    "                probs - tf.random.uniform(probs.shape)\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deprocess_image(x):\n",
    "    # Stack the single channeled black and white image to rgb values.\n",
    "    x = np.stack((x, x, x), 2)\n",
    "    # Undo preprocessing\n",
    "    x *= 255.0\n",
    "    # Convert to uint8 and clip to the valid range [0, 255]\n",
    "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "    return x\n",
    "\n",
    "\n",
    "# Iterate over the generated images and plot them with matplotlib.\n",
    "for i, pic in enumerate(pixels):\n",
    "    keras.preprocessing.image.save_img(\n",
    "        \"generated_image_{}.png\".format(i), deprocess_image(np.squeeze(pic, -1))\n",
    "    )\n",
    "\n",
    "display(Image(\"generated_image_0.png\"))\n",
    "display(Image(\"generated_image_1.png\"))\n",
    "display(Image(\"generated_image_2.png\"))\n",
    "display(Image(\"generated_image_3.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3875926bd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_type = \"B\"\n",
    "kernel_shape=pixel_cnn.layers[1].conv.kernel.get_shape()\n",
    "mask = np.zeros(shape=kernel_shape)\n",
    "mask[: kernel_shape[0] // 2, ...] = 1.0\n",
    "mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
    "if mask_type == \"B\":\n",
    "    mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
    "    \n",
    "plt.imshow(mask[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1cd36dd950>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
