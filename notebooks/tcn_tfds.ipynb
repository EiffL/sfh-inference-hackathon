{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b052cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Title: PixelCNN\n",
    "Author: [ADMoreau](https://github.com/ADMoreau)\n",
    "Date created: 2020/05/17\n",
    "Last modified: 2020/05/23\n",
    "Description: PixelCNN implemented in Keras.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Introduction\n",
    "PixelCNN is a generative model proposed in 2016 by van den Oord et al.\n",
    "(reference: [Conditional Image Generation with PixelCNN Decoders](https://arxiv.org/abs/1606.05328)).\n",
    "It is designed to generate images (or other data types) iteratively\n",
    "from an input vector where the probability distribution of prior elements dictates the\n",
    "probability distribution of later elements. In the following example, images are generated\n",
    "in this fashion, pixel-by-pixel, via a masked convolution kernel that only looks at data\n",
    "from previously generated pixels (origin at the top left) to generate later pixels.\n",
    "During inference, the output of the network is used as a probability ditribution\n",
    "from which new pixel values are sampled to generate a new image\n",
    "(here, with MNIST, the pixels values are either black or white).\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b320d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.1'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "tfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5817beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 21:31:04.649892: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float64, numpy=\n",
       "array([4.59480695e-02, 4.05681841e-02, 6.14476688e-02, 1.02433428e-01,\n",
       "       1.22986190e-01, 1.01852946e-01, 1.21698990e-01, 8.37925449e-02,\n",
       "       8.89969915e-02, 1.81623966e-01, 3.47551107e-01, 1.48228779e-01,\n",
       "       1.88104168e-01, 2.85926014e-01, 4.27734792e-01, 8.47152889e-01,\n",
       "       9.01352406e-01, 1.35696554e+00, 1.01610935e+00, 5.13705730e-01,\n",
       "       3.64999145e-01, 4.46566612e-01, 6.25037074e-01, 4.80371505e-01,\n",
       "       4.19634938e-01, 1.90336660e-01, 2.61428505e-01, 4.87600863e-01,\n",
       "       3.06690216e-01, 4.50582892e-01, 3.93242598e-01, 2.27611259e-01,\n",
       "       1.68406039e-01, 1.91149384e-01, 1.12246007e-01, 2.40402788e-01,\n",
       "       2.21817359e-01, 1.33597597e-01, 1.82019189e-01, 1.27638996e-01,\n",
       "       1.76021695e-01, 4.49072540e-01, 5.89619994e-01, 3.03729236e-01,\n",
       "       1.85595497e-01, 2.55545169e-01, 6.85951635e-02, 1.12479016e-01,\n",
       "       7.10858405e-02, 9.10805762e-02, 1.32100940e-01, 1.15806654e-01,\n",
       "       7.72362426e-02, 5.64680025e-02, 4.52835932e-02, 2.56494060e-02,\n",
       "       3.24830264e-02, 3.25568393e-02, 1.10930167e-01, 1.47753090e-01,\n",
       "       1.38693348e-01, 7.76704177e-02, 9.29370224e-02, 9.75756571e-02,\n",
       "       1.53563485e-01, 9.77702662e-02, 1.07061341e-01, 1.01446688e-01,\n",
       "       6.39793724e-02, 8.27882513e-02, 6.36100471e-02, 6.22796640e-02,\n",
       "       3.87642197e-02, 3.73098962e-02, 5.00894263e-02, 6.01285100e-02,\n",
       "       4.85793911e-02, 5.15654087e-02, 4.51481268e-02, 3.11778188e-02,\n",
       "       3.36803496e-02, 3.43522504e-02, 2.64296718e-02, 2.96329968e-02,\n",
       "       2.37530135e-02, 3.03212311e-02, 3.08495443e-02, 1.39330653e-02,\n",
       "       3.23569588e-02, 2.50167027e-02, 1.02314707e-02, 0.00000000e+00,\n",
       "       9.59394209e-04, 3.07468162e-03, 6.81827357e-03, 5.84822288e-03,\n",
       "       1.43709511e-03, 6.04604254e-04, 0.00000000e+00, 0.00000000e+00])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "dset = tfds.load('sfh', split='train')\n",
    "dset_interp = tfds.load('sfh_interp', split='train')\n",
    "sample = list(dset.take(5))[3]\n",
    "sample['SFR_Max']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e98084b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Code for the TCN adapted from https://github.com/philipperemy/keras-tcn\n",
    "\n",
    "def residual_block(x, training, dilation_rate, nb_filters, kernel_size, padding,\n",
    "                   activation='relu', dropout_rate=0, use_batch_norm=False):\n",
    "    # type: (Layer, bool, int, int, int, str, str, float, str, bool) -> Tuple[Layer, Layer]\n",
    "    \"\"\"Defines the residual block for the WaveNet TCN\n",
    "    Args:\n",
    "        x: The previous layer in the model\n",
    "        training: boolean indicating whether the layer should behave in training mode or in inference mode\n",
    "        dilation_rate: The dilation power of 2 we are using for this residual block\n",
    "        nb_filters: The number of convolutional filters to use in this block\n",
    "        kernel_size: The size of the convolutional kernel\n",
    "        padding: The padding used in the convolutional layers, 'same' or 'causal'.\n",
    "        activation: The final activation used in o = Activation(x + F(x))\n",
    "        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "        kernel_initializer: Initializer for the kernel weights matrix (Conv1D).\n",
    "        use_batch_norm: Whether to use batch normalization in the residual layers or not.\n",
    "    Returns:\n",
    "        A tuple where the first element is the residual model layer, and the second\n",
    "        is the skip connection.\n",
    "    \"\"\"\n",
    "    prev_x = x\n",
    "    for k in range(2):\n",
    "        x = tf.keras.layers.Conv1D(filters=nb_filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   dilation_rate=dilation_rate,\n",
    "                   padding=padding,\n",
    "                   activation=activation)(x)\n",
    "        if use_batch_norm:\n",
    "            x = tf.layers.batch_normalization(x)  # TODO should be WeightNorm here, but using batchNorm instead\n",
    "        #x = tf.nn.relu(x)\n",
    "        x = tf.keras.layers.SpatialDropout1D(rate=dropout_rate)(inputs=x, training=training)\n",
    "\n",
    "    # 1x1 conv to match the shapes (channel dimension).\n",
    "    prev_x = tf.keras.layers.Conv1D(nb_filters, 1, padding='same')(prev_x)\n",
    "    res_x = prev_x + x\n",
    "    res_x = tf.keras.activations.relu(res_x)\n",
    "    return res_x, x\n",
    "\n",
    "def process_dilations(dilations):\n",
    "    def is_power_of_two(num):\n",
    "        return num != 0 and ((num & (num - 1)) == 0)\n",
    "\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        return new_dilations\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(nb_filters, 1, padding=padding)(x)\n",
    "    skip_connections = []\n",
    "    for s in range(nb_stacks):\n",
    "        for d in dilations:\n",
    "            x, skip_out = residual_block(training=training,\n",
    "                                          dilation_rate=d,\n",
    "                                          nb_filters=nb_filters,\n",
    "                                          kernel_size=kernel_size,\n",
    "                                          padding=padding,\n",
    "                                          activation=activation,\n",
    "                                          dropout_rate=dropout_rate,\n",
    "                                          use_batch_norm=use_batch_norm)(x)\n",
    "            skip_connections.append(skip_out)\n",
    "    if use_skip_connections:\n",
    "        x = tf.keras.layers.add(skip_connections)\n",
    "    if not return_sequences:\n",
    "        x = x[:, -1, :]\n",
    "    return x\n",
    "\n",
    "\n",
    "paddings = tf.constant([[0, 0],[1,0],[0,0]])\n",
    "\n",
    "shift_layer = tf.keras.layers.Lambda(lambda x: tf.pad( x, paddings))\n",
    "cut_layer = tf.keras.layers.Lambda(lambda x: x[:,:-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de924174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "num_components = 2\n",
    "# Shape of the distribution\n",
    "event_shape = [1]\n",
    "# Utility function to compute how many parameters this distribution requires\n",
    "params_size = tfp.layers.MixtureNormal.params_size(num_components, event_shape)\n",
    "print(params_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ea81258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocessing(example):\n",
    "    return example['SFR_Max'], example['SFR_Max']\n",
    "\n",
    "def input_fn(mode='train', batch_size=64, dataset_name='sfh'):\n",
    "    \"\"\"\n",
    "    mode: 'train' or 'test'\n",
    "    \"\"\"\n",
    "    if mode == 'train':\n",
    "        dataset = tfds.load(dataset_name, split='train[:80%]')\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    else:\n",
    "        dataset = tfds.load(dataset_name, split='train[80%:]')\n",
    "    \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.map(preprocessing) # Apply data preprocessing\n",
    "    dataset = dataset.prefetch(-1)       # fetch next batches while training current one (-1 for autotune)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a89e6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Build the model based on the original paper\n",
    "\"\"\"\n",
    "\n",
    "N_TIMESTEPS = sample['SFR_Max'].shape[0]\n",
    "kernel_size=3\n",
    "\n",
    "pixel_cnn = keras.Sequential()\n",
    "\n",
    "pixel_cnn.add(shift_layer)\n",
    "pixel_cnn.add(cut_layer)\n",
    "pixel_cnn.add(tf.keras.layers.Conv1D(filters=16,\n",
    "                  kernel_size=kernel_size,\n",
    "                  dilation_rate=1,\n",
    "                  padding='causal',\n",
    "                  activation='relu'\n",
    "                  )\n",
    "             )\n",
    "\n",
    "for dilation_rate, nb_filters in zip([2, 4, 8, 16, 32], [16, 32, 64, 128, 256]):\n",
    "    pixel_cnn.add(\n",
    "        tf.keras.layers.Conv1D(filters=nb_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               dilation_rate=dilation_rate,\n",
    "               padding='causal',\n",
    "               activation='relu')\n",
    "    )\n",
    "\n",
    "pixel_cnn.add(keras.layers.Dense(params_size))\n",
    "pixel_cnn.add(tfp.layers.MixtureNormal(num_components, event_shape))\n",
    "\n",
    "pixel_cnn.build(input_shape=(64,N_TIMESTEPS,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "07459aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_16 (Lambda)           (64, 101, 1)              0         \n",
      "_________________________________________________________________\n",
      "lambda_17 (Lambda)           (64, 100, 1)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (64, 100, 16)             64        \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (64, 100, 16)             784       \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (64, 100, 32)             1568      \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (64, 100, 64)             6208      \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (64, 100, 128)            24704     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (64, 100, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (64, 100, 6)              1542      \n",
      "_________________________________________________________________\n",
      "mixture_normal_18 (MixtureNo multiple                  0         \n",
      "=================================================================\n",
      "Total params: 133,430\n",
      "Trainable params: 133,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pixel_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "62464822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#negloglik = lambda y, q: tf.reduce_sum(-q.log_prob(y),-1)\n",
    "negloglik = lambda y, q: tf.reduce_sum(-q.log_prob(y),-1)\n",
    "\n",
    "pixel_cnn.compile(loss=negloglik, optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3ad106a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
       "array([[-0.55462277, -0.55417085, -0.5563789 , -0.5633783 , -0.5682293 ,\n",
       "        -0.5633002 , -0.5678779 , -0.5597807 , -0.56082845, -0.58691984,\n",
       "        -0.6784665 , -0.5757804 , -0.5894922 , -0.6378108 , -0.7437508 ,\n",
       "        -1.3004949 , -1.3988876 , -2.469668  , -1.6291637 , -0.82887983,\n",
       "        -0.6932077 , -0.76193196, -0.962142  , -0.7952729 , -0.73762894,\n",
       "        -0.59150976, -0.6264014 , -0.8027282 , -0.65116394, -0.7660071 ,\n",
       "        -0.71590793, -0.60800886, -0.5828294 , -0.5906008 , -0.56464875,\n",
       "        -0.6136646 , -0.60468745, -0.5723578 , -0.58961827, -0.57210374,\n",
       "        -0.5881046 , -0.76476943, -0.9171527 , -0.6520439 , -0.59132105,\n",
       "        -0.62353414, -0.5586997 , -0.5678964 , -0.5587618 , -0.5637533 ,\n",
       "        -0.57395   , -0.56874514, -0.56084484, -0.559455  , -0.558672  ,\n",
       "        -0.55744153, -0.5574715 , -0.5559954 , -0.56791794, -0.5791496 ,\n",
       "        -0.57683074, -0.5628923 , -0.5663578 , -0.56888616, -0.58503664,\n",
       "        -0.5697901 , -0.5717716 , -0.5710018 , -0.5628634 , -0.5655082 ,\n",
       "        -0.56199443, -0.56186014, -0.56070447, -0.5587742 , -0.5603618 ,\n",
       "        -0.560951  , -0.5583546 , -0.5577583 , -0.5572661 , -0.5560827 ,\n",
       "        -0.55759424, -0.5563594 , -0.5552402 , -0.5555496 , -0.5552732 ,\n",
       "        -0.55660754, -0.557433  , -0.5571786 , -0.5568103 , -0.55668855,\n",
       "        -0.5557307 , -0.5548675 , -0.5548924 , -0.55608094, -0.5575396 ,\n",
       "        -0.55844307, -0.55869776, -0.5569964 , -0.55554795, -0.5579643 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist=pixel_cnn(tf.reshape(sample['SFR_Max'],(1,N_TIMESTEPS,1)))\n",
    "dist.log_prob(tf.cast(tf.reshape(sample['SFR_Max'],(1,N_TIMESTEPS,1)),dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "09e024d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /tmp/ipykernel_1617048/1019079822.py:2 None  *\n        lambda y, q: tf.reduce_sum(-q.log_prob(y),-1)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1315 log_prob  **\n        return self._call_log_prob(value, name, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1297 _call_log_prob\n        return self._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py:116 _log_prob\n        return self.tensor_distribution._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py:379 _log_prob\n        self._per_mixture_component_log_prob(x), axis=-1)  # [S, B]\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py:372 _per_mixture_component_log_prob\n        log_prob_x = self.components_distribution.log_prob(x)  # [S, B, k]\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1315 log_prob\n        return self._call_log_prob(value, name, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1297 _call_log_prob\n        return self._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py:116 _log_prob\n        return self.tensor_distribution._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/independent.py:290 _log_prob\n        self._sum_fn(), self.distribution.log_prob(x, **kwargs))\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1315 log_prob\n        return self._call_log_prob(value, name, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1297 _call_log_prob\n        return self._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/normal.py:190 _log_prob\n        x / scale, self.loc / scale)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n        raise e\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n        return func(x, y, name=name)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1543 truediv\n        return _truediv_python3(x, y, name)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1482 _truediv_python3\n        return gen_math_ops.real_div(x, y, name=name)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:7515 real_div\n        \"RealDiv\", x=x, y=y, name=name)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal\n        compute_device)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal\n        op_def=op_def)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2042 __init__\n        control_input_ops, op_def)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 64 and 100 for '{{node lambda/sequential_16_mixture_normal_18_tensor_coercible/log_prob/sequential_16_mixture_normal_18_MixtureSameFamily_independent_normal_tensor_coercible/log_prob/sequential_16_mixture_normal_18_MixtureSameFamily_independent_normal_IndependentNormal_Normal/log_prob/truediv}} = RealDiv[T=DT_FLOAT](lambda/sequential_16_mixture_normal_18_tensor_coercible/log_prob/pad_sample_dims/Reshape, sequential_16/mixture_normal_18/MixtureSameFamily/independent_normal/IndependentNormal/Softplus)' with input shapes: [64,1,100], [64,100,2,1].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1617048/1738391320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sfh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpixel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /tmp/ipykernel_1617048/1019079822.py:2 None  *\n        lambda y, q: tf.reduce_sum(-q.log_prob(y),-1)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1315 log_prob  **\n        return self._call_log_prob(value, name, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1297 _call_log_prob\n        return self._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py:116 _log_prob\n        return self.tensor_distribution._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py:379 _log_prob\n        self._per_mixture_component_log_prob(x), axis=-1)  # [S, B]\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py:372 _per_mixture_component_log_prob\n        log_prob_x = self.components_distribution.log_prob(x)  # [S, B, k]\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1315 log_prob\n        return self._call_log_prob(value, name, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1297 _call_log_prob\n        return self._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py:116 _log_prob\n        return self.tensor_distribution._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/independent.py:290 _log_prob\n        self._sum_fn(), self.distribution.log_prob(x, **kwargs))\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1315 log_prob\n        return self._call_log_prob(value, name, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py:1297 _call_log_prob\n        return self._log_prob(value, **kwargs)\n    /linkhome/rech/genaim01/ucf27qy/.local/lib/python3.7/site-packages/tensorflow_probability/python/distributions/normal.py:190 _log_prob\n        x / scale, self.loc / scale)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n        raise e\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n        return func(x, y, name=name)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1543 truediv\n        return _truediv_python3(x, y, name)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1482 _truediv_python3\n        return gen_math_ops.real_div(x, y, name=name)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:7515 real_div\n        \"RealDiv\", x=x, y=y, name=name)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal\n        compute_device)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal\n        op_def=op_def)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2042 __init__\n        control_input_ops, op_def)\n    /gpfslocalsup/pub/anaconda-py3/2021.05/envs/tensorflow-gpu-2.6.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 64 and 100 for '{{node lambda/sequential_16_mixture_normal_18_tensor_coercible/log_prob/sequential_16_mixture_normal_18_MixtureSameFamily_independent_normal_tensor_coercible/log_prob/sequential_16_mixture_normal_18_MixtureSameFamily_independent_normal_IndependentNormal_Normal/log_prob/truediv}} = RealDiv[T=DT_FLOAT](lambda/sequential_16_mixture_normal_18_tensor_coercible/log_prob/pad_sample_dims/Reshape, sequential_16/mixture_normal_18/MixtureSameFamily/independent_normal/IndependentNormal/Softplus)' with input shapes: [64,1,100], [64,100,2,1].\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = input_fn(mode='train', batch_size=64, dataset_name='sfh')\n",
    "\n",
    "pixel_cnn.fit(data, epochs=10, steps_per_epoch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "36857606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 100, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100, 15)           195       \n",
      "_________________________________________________________________\n",
      "mixture_normal_17 (MixtureNo multiple                  0         \n",
      "=================================================================\n",
      "Total params: 219\n",
      "Trainable params: 219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "event_shape = [1]\n",
    "num_components = 5\n",
    "params_size = tfp.layers.MixtureNormal.params_size(num_components, event_shape)\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Dense(12, activation='relu', input_shape=(100,1)),\n",
    "  keras.layers.Dense(params_size, activation=None),\n",
    "  tfp.layers.MixtureNormal(num_components, event_shape)\n",
    "])\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b19c8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5dc2fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26601d0bd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = np.random.random((28,1))\n",
    "plt.imshow(pixel_cnn.predict(seq).reshape(28,1))\n",
    "plt.show()\n",
    "plt.imshow(seq)\n",
    "plt.show()\n",
    "plt.imshow(seq-pixel_cnn.predict(seq).reshape(28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ac987f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f266020dc50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(seq, vmin=-5, vmax=5, cmap='jet', aspect='auto')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(pixel_cnn.predict(seq).reshape(28,1), vmin=-5, vmax=5, cmap='jet', aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b645bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(28, 1, 1), dtype=float32, numpy=\n",
       "array([[[ 2.0971757e-01]],\n",
       "\n",
       "       [[ 2.0853369e-01]],\n",
       "\n",
       "       [[ 5.7056743e-01]],\n",
       "\n",
       "       [[ 5.2681899e-01]],\n",
       "\n",
       "       [[ 1.1434085e-02]],\n",
       "\n",
       "       [[-1.4872286e-03]],\n",
       "\n",
       "       [[ 1.9894464e-01]],\n",
       "\n",
       "       [[ 6.9658109e-03]],\n",
       "\n",
       "       [[ 2.4975747e-02]],\n",
       "\n",
       "       [[ 3.4848716e-02]],\n",
       "\n",
       "       [[ 4.1500636e-05]],\n",
       "\n",
       "       [[ 6.5648180e-01]],\n",
       "\n",
       "       [[ 1.0504401e-01]],\n",
       "\n",
       "       [[ 2.4598925e-03]],\n",
       "\n",
       "       [[-3.7073959e-03]],\n",
       "\n",
       "       [[ 1.7077190e-01]],\n",
       "\n",
       "       [[ 3.3144313e-03]],\n",
       "\n",
       "       [[ 6.1454052e-01]],\n",
       "\n",
       "       [[ 1.5206153e-02]],\n",
       "\n",
       "       [[ 1.9228107e-01]],\n",
       "\n",
       "       [[ 2.7804214e-01]],\n",
       "\n",
       "       [[ 1.6186319e-01]],\n",
       "\n",
       "       [[ 6.1516356e-01]],\n",
       "\n",
       "       [[-1.7056708e-01]],\n",
       "\n",
       "       [[ 5.4616743e-01]],\n",
       "\n",
       "       [[ 2.5906002e-03]],\n",
       "\n",
       "       [[-2.8486946e-03]],\n",
       "\n",
       "       [[-3.9793984e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_cnn(seq).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15a6da68",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MixtureNormal' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9a8e655d0baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpixel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MixtureNormal' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "pixel_cnn.layers[-1].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a85c4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Build the model based on the original paper\n",
    "\"\"\"\n",
    "\n",
    "inputs = keras.Input(shape=(28,1))\n",
    "x = PixelConvLayer(\n",
    "    mask_type=\"A\", filters=128, kernel_size=7, activation=\"relu\", padding=\"same\"\n",
    ")(inputs)\n",
    "\n",
    "for _ in range(n_residual_blocks):\n",
    "    x = ResidualBlock(filters=128)(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    x = PixelConvLayer(\n",
    "        mask_type=\"B\",\n",
    "        filters=128,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        activation=\"relu\",\n",
    "        padding=\"valid\",\n",
    "    )(x)\n",
    "\n",
    "#out = keras.layers.Conv1D(\n",
    "#    filters=1, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"valid\"\n",
    "#)(x)\n",
    "\n",
    "out = tfp.layers.MixtureNormal(num_components, event_shape)(x)\n",
    "\n",
    "\n",
    "pixel_cnn = keras.Model(inputs, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "negloglik = lambda y, q: -q.log_prob(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2324e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 1)]           0         \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer (PixelConvL (None, 28, 128)           1024      \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "residual_block_2 (ResidualBl (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "residual_block_3 (ResidualBl (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "residual_block_4 (ResidualBl (None, 28, 128)           49472     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_6 (PixelCon (None, 28, 128)           16512     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_7 (PixelCon (None, 28, 128)           16512     \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 28, 1)             129       \n",
      "=================================================================\n",
      "Total params: 281,537\n",
      "Trainable params: 281,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "pixel_cnn.compile(optimizer=adam, loss=negloglik)\n",
    "\n",
    "pixel_cnn.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "350d26ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(pixel_cnn, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn.fit(\n",
    "    x=data, y=data, batch_size=128, epochs=50, validation_split=0.1, verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f4251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc522f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Demonstration\n",
    "The PixelCNN cannot generate the full image at once. Instead, it must generate each pixel in\n",
    "order, append the last generated pixel to the current image, and feed the image back into the\n",
    "model to repeat the process.\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Create an empty array of pixels.\n",
    "batch = 4\n",
    "pixels = np.zeros(shape=(batch,) + (pixel_cnn.input_shape)[1:])\n",
    "batch, rows, cols, channels = pixels.shape\n",
    "\n",
    "# Iterate over the pixels because generation has to be done sequentially pixel by pixel.\n",
    "for row in tqdm(range(rows)):\n",
    "    for col in range(cols):\n",
    "        for channel in range(channels):\n",
    "            # Feed the whole array and retrieving the pixel value probabilities for the next\n",
    "            # pixel.\n",
    "            probs = pixel_cnn.predict(pixels)[:, row, col, channel]\n",
    "            # Use the probabilities to pick pixel values and append the values to the image\n",
    "            # frame.\n",
    "            pixels[:, row, col, channel] = tf.math.ceil(\n",
    "                probs - tf.random.uniform(probs.shape)\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deprocess_image(x):\n",
    "    # Stack the single channeled black and white image to rgb values.\n",
    "    x = np.stack((x, x, x), 2)\n",
    "    # Undo preprocessing\n",
    "    x *= 255.0\n",
    "    # Convert to uint8 and clip to the valid range [0, 255]\n",
    "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "    return x\n",
    "\n",
    "\n",
    "# Iterate over the generated images and plot them with matplotlib.\n",
    "for i, pic in enumerate(pixels):\n",
    "    keras.preprocessing.image.save_img(\n",
    "        \"generated_image_{}.png\".format(i), deprocess_image(np.squeeze(pic, -1))\n",
    "    )\n",
    "\n",
    "display(Image(\"generated_image_0.png\"))\n",
    "display(Image(\"generated_image_1.png\"))\n",
    "display(Image(\"generated_image_2.png\"))\n",
    "display(Image(\"generated_image_3.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b24900f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e39ae21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3875926bd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_type = \"B\"\n",
    "kernel_shape=pixel_cnn.layers[1].conv.kernel.get_shape()\n",
    "mask = np.zeros(shape=kernel_shape)\n",
    "mask[: kernel_shape[0] // 2, ...] = 1.0\n",
    "mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
    "if mask_type == \"B\":\n",
    "    mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
    "    \n",
    "plt.imshow(mask[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "969f6172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1cd36dd950>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
