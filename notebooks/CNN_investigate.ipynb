{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90dfde6b",
   "metadata": {},
   "source": [
    "Notebook to investigate CNN - mass - flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86ccab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# import numpy as np\n",
    "#!pip install pandas\n",
    "# import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfkl\n",
    "import tensorflow_datasets as tfds\n",
    "# import my_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "data_dir='/gpfsscratch/rech/qrc/commun/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0dec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2377238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def Model(nb_summaries):\n",
    "    \"\"\" Creates a small fully connected network\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        tfkl.Input(shape=(143)),\n",
    "        tfkl.Dense(16, activation='relu'),\n",
    "        tfkl.Dense(32, activation='relu'),\n",
    "        tfkl.Dense(64, activation='relu'),\n",
    "        tfkl.Dense(128, activation='relu'),\n",
    "        tfkl.Dense(nb_summaries, activation='softplus')\n",
    "        ])\n",
    "\n",
    "\n",
    "# def preprocessing(example):\n",
    "#     img = tf.math.asinh(example['image'] / tf.constant(scaling) / 3. )\n",
    "#   # We return the image as our input and output for a generative model\n",
    "#   return img\n",
    "\n",
    "def input_fn(mode='train', batch_size=64):\n",
    "    \"\"\"\n",
    "    mode: 'train' or 'test'\n",
    "    \"\"\"\n",
    "    if mode == 'train':\n",
    "        dataset = tfds.load('sfhsed', split='train[:80%]', data_dir=data_dir)\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    else:\n",
    "        dataset = tfds.load('sfhsed', split='train[80%:]')\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "#     dataset = dataset.map(preprocessing) # Apply data preprocessing\n",
    "    dataset = dataset.prefetch(-1)  # fetch next batches while training current one (-1 for autotune)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2721f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(1)\n",
    "# print(model.summary)\n",
    "# dset = input_fn()\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "#               loss=tf.keras.losses.MSE)\n",
    "\n",
    "# history = model.fit(x=dset['flux'], y=dset['quantile'][4], epochs=20)\n",
    "\n",
    "# plt.plot(history.loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27949c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                2304      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 13,409\n",
      "Trainable params: 13,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0043989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2625a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e95d8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {flux: (64, 143), mass: (64, 100), object_id: (64,), quantile: (64, 9), time: (64, 100)}, types: {flux: tf.float32, mass: tf.float32, object_id: tf.float32, quantile: tf.float32, time: tf.float32}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1679bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_quantile = model(x['flux'])\n",
    "        loss = tf.keras.losses.MSE(x['quantile'][4], predicted_quantile)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9321c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114dde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "nb_epochs = 10\n",
    "t = trange(nb_epochs, desc='training')\n",
    "for epoch in t:\n",
    "    for i, features in enumerate(dset):\n",
    "        loss = train_step(features)\n",
    "        loss_history.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818837c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=dset['flux'], y=dset['quantile'][4], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65ae56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
